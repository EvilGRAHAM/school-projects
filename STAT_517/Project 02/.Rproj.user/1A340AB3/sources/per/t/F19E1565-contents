---
title: "Analysis of EA NHL Results"
author: "Scott Graham 10131323"
date: "December 06, 2017"
header-includes:
  - \newcommand{\Prob}{\operatorname{P}}
  - \newcommand{\E}{\operatorname{E}}
  - \newcommand{\Var}{\operatorname{Var}}
  - \newcommand{\Cov}{\operatorname{Cov}}
  - \newcommand{\se}{\operatorname{se}}
  - \newcommand{\re}{\operatorname{re}}
  - \newcommand{\ybar}{{\overline{Y}}}
  - \newcommand{\phat}{{\hat{p}}}
  - \newcommand{\that}{{\hat{T}}}
  - \newcommand{\med}{{\tilde{Y}}}
output:
  pdf_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

set.seed(5609)

library(knitr, warn.conflicts = FALSE, quietly = TRUE)
library(kableExtra, warn.conflicts = FALSE, quietly = TRUE)
library(tidyverse, warn.conflicts = FALSE, quietly = TRUE)
library(ggfortify, warn.conflicts = FALSE, quietly = TRUE)
library(magrittr, warn.conflicts = FALSE, quietly = TRUE)
library(flatr, warn.conflicts = FALSE, quietly = TRUE)
library(lmtest, warn.conflicts = FALSE, quietly = TRUE)
library(glmnet, warn.conflicts = FALSE, quietly = TRUE)

theme_minimal2 <- theme_minimal() %>%  theme_set()
theme_minimal2 <-
  theme_update(
    panel.border = element_rect(
      linetype = "solid"
      ,colour = "grey92"
      ,fill = NA
    )
    ,strip.background = element_rect(
      linetype = "solid"
      ,colour = "grey92"
      ,fill = NA
    )
  )

hockey_data <- 
  "http://grahamst.at/projects/STAT_541/Final_Project/data/hockey_stats.csv" %>% 
  read_csv() %>% 
  rename(`Day of the Week` = `Day of Week`) %>% 
  mutate(
    `P1 Win` = as.factor(`P1 Win`)
    ,`P2 - P1 Goals` = P2 - P1
    ,`Shot Differential` = `P2 Shots` - `P1 Shots`
    ,`Hit Differential` = `P2 Hits` - `P1 Hits`
    ,`Day of the Week` = as.factor(`Day of the Week`)
    ,`Scored 1st Boolean (P2)` = if_else(`Scored 1st` == "P2", 1, 0)
    ,Shots = `P1 Shots` + `P2 Shots`
    ,Hits = `P1 Hits` + `P2 Hits`
    ,ToA = `P1 ToA` + `P2 ToA`
    ,Passing = `P1 Passing` + `P2 Passing`
    ,PM = `P1 PM` + `P2 PM`
    ,Powerplays = `P1 Powerplays` + `P2 Powerplays`
    ,`Penalty Shots` = `P1 Penalty Shots` + `P2 Penalty Shots`
    ,Faceoffs = `P1 Faceoffs` + `P2 Faceoffs`
    ,`Offensive Faceoffs` = `P1 Offensive Faceoffs` + `P2 Offensive Faceoffs`
    ,Breakaways = `P1 Breakaways` + `P2 Breakaways`
  )

day_of_week_conv <- 
  c(
    "0" = "Sunday"
    ,"1" = "Monday"
    ,"2" = "Tuesday"
    ,"3" = "Wednesday"
    ,"4" = "Thursday"
    ,"5" = "Friday"
    ,"6" = "Saturday"
  )

```

\newpage

# Introduction
## Data
This data set contains the results of 217 games played in the video games NHL 12, 13, and 17, played between 2 friends, Tim and Randy (P1 and P2 respectively) (Randy, 2017). They compiled an incredibly detailed gamelog for each game played, with well over 50 variables recorded, and period by period breakdowns. For those not familiar, the NHL series of video games is developed by EA Sports, and serves as the most readily available means of simulating real NHL.(EA, 2017) While obviously not perfect, it serves as a decent proxy for predicting the results of hockey games in general, as many of the same principles apply.

Since the outcome of a game is determined by the end score, any variables referencing the goals scored have been removed, as they serve little to know interest in the prediction of games. However there is one exception, and that is who scored the first goal of the game, which in itself seemed to be an interesting possible predictor. Instead more periphery statistics will be looked at, such as hits, shots, face off percentage, breakaways, penalties, and other such things. As well, a 1 game lagged result term has been included, to see if any autocorrelation exists within the results, and if it plays a significant role in the prediction process.


## Analysis
In this report, a Binomial and Log Linear LASSO model will be used in the variable selection and coefficient estimation process, in addition to the usual step wise methods. As previously mentioned, the autocorrelation of the results will also be examined to see if such an effect exists. Finally a variety of visual tools will be used in the exploratory analysis portion of the paper, in an effort to understand the relationships within the data.

For the LASSO model, the package `glmnet` is used, to perform an elastic-net version of the LASSO model(Hastie et al, 2014). All the data cleaning is done with the usage of a variety of packages from the "tidyverse". This includes the packages `dplyr`, `tidyr`, `magrittr`, and `tibble`.(Wickham, 2017) As well, the `flatr` package is used to transform contingency tables into "tidy" data frames, where each variable has its own column for each observation. `flatr` was created by myself in an effort to simplify some of the cleaning done for this course. Finally `ggplot2` is used as the primary visualization method, due to its flexibility in creating visualizations, and overall better appearance than base graphics.


## Research Question
What periphery (non-goal related) statistics can be used to predict the outcome of a hockey game?



# Exploratory Analysis
## Game Results
```{r Game Results}
hockey_data %>% 
  mutate(
    `P2` = if_else(`P2 - P1 Goals` > 0, `P2 - P1 Goals`, as.integer(0))
    ,`P1` = if_else(`P2 - P1 Goals` <= 0, `P2 - P1 Goals`, as.integer(0))
  ) %>% 
  select(
    Game
    ,`P1`
    ,`P2`
  ) %>% 
  gather(
    key = Player
    ,value = `Goal Differential`
    ,-Game
  ) %>% 
  filter(`Goal Differential` != 0) %>% 
  ggplot(
    aes(
      x = Game
      ,y = `Goal Differential`
      ,fill = `Player`
    )
  ) +
  geom_vline(
    data = 
      hockey_data %>% 
      group_by(Version) %>% 
      summarize(Game = min(Game))
    ,aes(xintercept = Game)
    ,linetype = "dashed"
    ,size = 0.5
  ) +
  geom_col() +
  scale_fill_brewer(
    type = "qual"
    ,palette = "Set2"
  )
```

From this, it is fairly obvious that P2 wins the majority of the games (`r round((1 - (mean(unclass(hockey_data$"P1 Win")) - 1)) * 100, 2)`\%), as well as by a fairly decent margin (`r round(mean(hockey_data$"P2 - P1 Goals"), 4)` goals per game). The dotted lines represent a change in version, from 12 to 13 to 17.


## Correlation Matrix
One of the primary issues with any regression model is collinearity among the predictors. To analyse this, a correlation matrix has been generated, presented as the corresponding visualization. Any of the variables that are of numeric type are evaluated.

```{r Cor Matrix}
hockey_data %>%
  select_if(.predicate = is.numeric) %>%
  select(
    -c(
      Game
      ,Version
      ,`P2 - P1 Goals`
    )
    ,-ends_with("Differential")
  ) %>% 
  cor() %>% 
  as.data.frame() %>%  
  rownames_to_column() %>% 
  as.tibble() %>% 
  gather(
    key = Column
    ,value = Correlation
    ,-rowname
  ) %>% 
  rename(Row = rowname) %>% 
  ggplot(
    aes(
      x = Column
      ,y = Row
      ,fill = Correlation
    )
  ) +
  geom_raster() +
  scale_fill_distiller(
    type = "div"
    ,palette = "RdBu"
    ,limits = c(-1, 1)
  ) +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1)
    ,axis.title.x = element_blank()
    ,axis.title.y = element_blank()
  )
```

There appears to be be fairly small correlation among the different variables, with a few exceptions. Time of Attack (ToA) and Shots appear to have a somewhat significant correlation, which is expected, as the more time spent in the attacking zone, the more shots are generated. Hits and face offs appear to be correlated, which is interesting, as I can't see a reason why this would occur.


## Distribution of Goals
The underlying distribution of goals may also be of interest. I expect a right-skewed distribution, as most games typically have `r round(cbind(hockey_data$P1, hockey_data$P2) %>% mean(), 4)` goals for each player. As well, the domain of the distribution is $[0, \infty)$, as negative goals can't be awarded. The distribution of their difference is looked at as well, which should be bimodal, as no ties exist in the data set or in the modern NHL.

```{r Goal Distribution}
hockey_data %>% 
  select(
    P1
    ,P2
    ,`P2 - P1 Goals`
  ) %>% 
  gather(
    key = "Variable"
    ,value = "Goals"
  ) %>% 
  mutate(
    Variable = 
      factor(
        x = Variable
        ,levels = c("P1", "P2", "P2 - P1 Goals")
      )
  ) %>% 
  ggplot(
    aes(
      x = Goals
      ,colour = Variable
    )
  ) +
  geom_density() +
  facet_wrap(
    facet = ~ Variable
    ,ncol = 1
  ) +
  scale_colour_brewer(
    type = "qual"
    ,name = "Variable"
    ,palette = "Set2"
  )
```

P2's distribution matches what was expected, as well as the difference. P1's on the other hand appears to be more symmetric than expected, possibly due to a decreased likelihood of him running up the score.

Another factor to explore is if the version of the game changes the distribution. Besides updating player rosters, various game play changes are made, which may effect each player differently.

```{r Goal Distribution by Version}
hockey_data %>% 
  select(
    P1
    ,P2
    ,`P2 - P1 Goals`
    ,Version
  ) %>% 
  gather(
    key = "Variable"
    ,value = "Goals"
    ,-Version
  ) %>% 
  mutate(
    Variable = 
      factor(
        x = Variable
        ,levels = c("P1", "P2", "P2 - P1 Goals")
      )
  ) %>% 
  ggplot(
    aes(
      x = Goals
      ,colour = Variable
    )
  ) +
  geom_density() +
  facet_grid(facet = Version ~ Variable) +
  scale_colour_brewer(
    type = "qual"
    ,name = "Variable"
    ,palette = "Set2"
  )
```

It appears version does not play a significant role in determining the distribution of goals. This can be seen by reading the chart from top to bottom, and not seeing significant changes in the shape of the kernel density estimators.


## Goals vs. Shots
> "You miss 100% of the shots you don't take."
> - Wayne Gretzky

An important relationship in hockey is that of Goals and Shots. Reasonably assumed, the more shots you take, the more goals you score. The question is though, does this relationship differ for each player?

```{r GvS}
hockey_data_GvS <- 
  hockey_data %>% 
  select(
    Game
    ,`P1 Goals` = P1
    ,`P2 Goals` = P2
    ,`P1 Shots`
    ,`P2 Shots`
  ) %>% 
  gather(
    key = Variable
    ,value = Value
    ,-Game
  ) %>% 
  mutate(
    Player = 
      if_else(
        grepl(pattern = "P1 *", x = .$Variable), "P1", "P2"
      )
    ,Statistic =
      if_else(
        grepl(pattern = "* Goals", x = .$Variable), "Goals", "Shots"
      )
  ) %>% 
  select(-Variable) %>% 
  spread(
    key = Statistic
    ,value = Value
  ) %>% 
  mutate(Player = as.factor(Player))

hockey_data_GvS %>% 
  ggplot(
    aes(
      x = Shots
      ,y = Goals
      ,colour = Player
    )
  ) +
  geom_point(
    data = 
      hockey_data_GvS %>% 
      select(-Player)
    ,colour="grey92"
    ,alpha = 0.75
  ) +
  geom_point() +
  geom_smooth(
    method = "loess"
    ,se = FALSE
  ) +
  geom_smooth(
    method = "lm"
    ,se = FALSE
  )  +
  facet_grid(facet = ~ Player) +
  scale_colour_brewer(
    type = "qual"
    ,name = "Player"
    ,palette = "Set2"
  )
```

As one can see, clearly P2 scores more goals on average (`r round(mean(hockey_data$P2), 4)` vs. `r round(mean(hockey_data$P1), 4)`). However the slopes of the two lines appear to differ, with P1's being higher than P2's. This leads to two possible conclusions:

1. P1 should shoot the puck more often, as his expected goals will rise at a faster rate than P2's
2. P2 shouldn't worry as much about getting lots of shots, but primarily focus on getting high danger chances (chances close to the net)


## Autocorrelation
Autocorrelation measures the correlation between $\left(X_{t-k}, X_{t}\right), t=k, k+1\dots,n$. It is primarily used in time series analysis to measure the tendency for a time series to be mean reverting (negative autocorrelation) or a tendency to go on long runs in one direct or the other (positive autocorrelation). This is primarily used in the analysis of stock returns, but can be applied to any time series.

What we wish to measure is if P1 wins the last game, is he more or less likely to win the following game? This can be accomplished both graphically, and through the use of a Durbin-Watson test(Oklahoma State, 1999). More specifically, the Durbin-Watson statistic tests:
$$
  H_{0}: \text{Autocorrelation} = 0
$$
$$
  H_{1}: \text{Autocorrelation} \neq 0
$$

```{r Autocorrelation Plot}
hockey_data_acf <- 
  hockey_data %>%
  mutate(P1_Win_Bool = if_else(`P1 Win` == "Yes", 1, 0)) %>% 
  select(P1_Win_Bool) %>% 
  acf(plot = FALSE)

hockey_data_acf

data.frame(Lag = hockey_data_acf$lag, Autocorrelation = hockey_data_acf$acf) %>% 
  ggplot(
    aes(
      x = Lag
      ,y = Autocorrelation
    )
  ) +
  geom_hline(
    aes(
      yintercept = 0
    )
    ,linetype = "dotted"
  ) +
  geom_segment(
    aes(
      xend = Lag
      ,yend = 0
    )
  ) +
  geom_smooth(
    linetype = 0
    ,method = "lm"
    ,formula = y ~ 1
  )
```

As one can see, the autocorrelation for $k=1$ is not larger than the 95\% confidence interval, as shown by the grey band. Since we are interested in the case for $k=1$, we can confirm this by modeling:
$$
  \operatorname{Logit}\left( \text{P1 Wins} \right) =
  \alpha + \beta_{1}\text{Previous Game's Result}
$$

and looking at the Wald Statistic, and the Durbin-Watson Statistic from the `lmtest` package, using the function `dwtest`.

```{r Autocorrelation Test, echo=TRUE}
hockey_acf_logit <- 
  hockey_data %>%
  glm(
    formula = `P1 Win` ~ `P1 Previous Game`
    ,family = binomial
    ,data = .
  )
summary(hockey_acf_logit)
lmtest::dwtest(hockey_acf_logit, alternative = "two.sided")
```

The Wald Statistic allows us to reject the null hypothesis that the previous games result has an effect on the game at hand, and the Durbin-Watson Statistics also confirms this result, both based on the sample.



# Modeling
## Contingency Table Model
### Contingency Table
A very simplistic model is considered as a starting point for the modeling process, as well as a means of showing of the 3 main functions of the `flatr` package. The contingency table has 3 dimensions; Winner, Home Team, and who scored 1st.

```{r CT}
hockey_ct_summary <- 
  hockey_data %>% 
  select(
    `P1 Win`
    ,`P1 Home`
    ,`Scored 1st`
  ) %>% 
  group_by_all() %>% 
  count() %>% 
  ungroup()

hockey_ct <- 
  array(
    data =
      c(
        hockey_ct_summary %>% 
          filter(
            `P1 Win` == "Yes"
            ,`P1 Home` == "H"
            ,`Scored 1st` == "P1"
          ) %>% 
          select(n) %>% 
          as.numeric()
        ,hockey_ct_summary %>% 
          filter(
            `P1 Win` == "Yes"
            ,`P1 Home` == "H"
            ,`Scored 1st` == "P2"
          ) %>% 
          select(n) %>% 
          as.numeric()
        ,hockey_ct_summary %>% 
          filter(
            `P1 Win` == "No"
            ,`P1 Home` == "H"
            ,`Scored 1st` == "P1"
          ) %>% 
          select(n) %>% 
          as.numeric()
        ,hockey_ct_summary %>% 
          filter(
            `P1 Win` == "No"
            ,`P1 Home` == "H"
            ,`Scored 1st` == "P2"
          ) %>% 
          select(n) %>% 
          as.numeric()
        ,hockey_ct_summary %>% 
          filter(
            `P1 Win` == "Yes"
            ,`P1 Home` == "A"
            ,`Scored 1st` == "P1"
          ) %>% 
          select(n) %>% 
          as.numeric()
        ,hockey_ct_summary %>% 
          filter(
            `P1 Win` == "Yes"
            ,`P1 Home` == "A"
            ,`Scored 1st` == "P2"
          ) %>% 
          select(n) %>% 
          as.numeric()
        ,hockey_ct_summary %>% 
          filter(
            `P1 Win` == "No"
            ,`P1 Home` == "A"
            ,`Scored 1st` == "P1"
          ) %>% 
          select(n) %>% 
          as.numeric()
        ,hockey_ct_summary %>% 
          filter(
            `P1 Win` == "No"
            ,`P1 Home` == "A"
            ,`Scored 1st` == "P2"
          ) %>% 
          select(n) %>% 
          as.numeric()
      )
    ,dim = c(2, 2, 2)
    ,dimnames = 
      list(
        Scored_1st = c("P1", "P2")
        ,Winner = c("P1", "P2")
        ,Home = c("P1", "P2")
      )
  )
hockey_ct
```

### flatten_ct
`flatten_ct` takes a $i \times j \times k$ contingency table, and turns it into a data frame. The 3 columns of the data frame are populated by the names of the levels of the table, and are repeated the appropriate number of times. It also plays well with `magrittr`'s `%>%`, or pipe. It is equivalent to writing nested functions. For example `10 %>% rnorm() %>% mean()` is equivalent to `mean(rnorm(10))`.

Below is a sample of what the output of the function, and proof it matches the contingency table when summarized.

```{r CT Flatten, echo=TRUE}
hockey_ct %>% 
  flatten_ct() %>% 
  head() %>% 
  kable(digits = 4, format = "latex", booktabs = T) %>% 
  kable_styling()

hockey_ct %>% 
  flatten_ct() %>% 
  group_by_all() %>% 
  count() %>% 
  kable(digits = 4, format = "latex", booktabs = T) %>% 
  kable_styling()

```

### Regression Models and Goodness of Fit Tests
A Logistic regression model has been fitted, where:
$$
  \operatorname{Logit}\left( \text{P1 Wins} \right) =
  \alpha + \beta_{1}\text{Scored First} + \beta_{2}\text{Home Team}
$$

As well a log linear function is fitted, where:
$$
  \ln(\mu) =
  \alpha + \beta_{1}\text{Scored First} + \beta_{2}\text{P1 Wins} + \beta_{3}\text{Home Team}
$$

```{r CT Model, echo=TRUE}
hockey_ct_logit <- 
  hockey_ct %>% 
  flatten_ct() %>% 
  glm(
    Winner ~ Scored_1st + Home
    ,family = binomial
    ,data = .
  )
summary(hockey_ct_logit)
goodness_of_fit(model = hockey_ct_logit, type = "Chisq")
goodness_of_fit(model = hockey_ct_logit, type = "Gsq")

hockey_ct_loglin <- 
  hockey_ct %>% 
  flatten_ct() %>% 
  group_by_all() %>% 
  count() %>% 
  ungroup() %>% 
  glm(
    n ~ (Scored_1st + Winner + Home)^2
    ,family = poisson
    ,data = .
  )
summary(hockey_ct_loglin)
goodness_of_fit_loglin(model = hockey_ct_loglin, type = "Chisq")
goodness_of_fit_loglin(model = hockey_ct_loglin, type = "Gsq")
```

`goodness_of_fit` and `goodness_of_fit_loglin` perform the goodness of fit tests for binomial models and log linear models respectively. Eventually I plan on putting them both in the same function call. As well, they have a nice looking printout, detailing the model, test statistic, degrees of freedom and the p-value.

The models themselves aren't terribly interesting, as there aren't many statistically significant coefficients. However both of them fail to reject the null hypothesis of the model fits the data in the goodness of fit tests, so at least that's a start.


## Full Model
The full model used is the model that contains the majority of the predictors.
```{r Full Model 01, echo=TRUE}
hockey_full_logit_01<- 
  hockey_data %>% 
  glm(
    formula = 
      `P1 Win` ~
      `P1 Previous Game` + `P1 Home` + `P1 Team` + `Scored 1st` + 
      `P1 Shots` + `P2 Shots` + `P1 Hits` + `P2 Hits` + `P1 ToA` + `P2 ToA` + 
      `P1 Passing` + `P2 Passing` + `P1 Faceoffs` + `P2 Faceoffs` + 
      `P1 Offensive Faceoffs` + `P2 Offensive Faceoffs` + `P1 PM` + `P2 PM` + 
      `P1 Powerplays` + `P2 Powerplays` + `P1 Penalty Shots` + `P2 Penalty Shots` + 
      `P1 Breakaways` + `P2 Breakaways`
    ,family = binomial
    ,data = .
  )
summary(hockey_full_logit_01)
```

First thing to notice is that R doesn't like the P1 Home variable, and defines it as a singularity, so it should be removed. As well, P1 Team is taken out, as it makes the model much more complicated, while adding no statistically significant benefit. As well, thanks to the analysis on the autocorrelation term, we can remove that as well. A model with interaction terms would be useful to look at, however due to the number of parameter, this is not feasible as $p>n$.

```{r Full Model 02}
hockey_full_logit_02<- 
  glm(
    formula = 
      `P1 Win` ~
      `Scored 1st` + 
      `P1 Shots` + `P2 Shots` +
      `P1 Hits` + `P2 Hits` +
      `P1 ToA` + `P2 ToA` +
      `P1 Passing` + `P2 Passing` + 
      `P1 Faceoffs` + `P2 Faceoffs` +
      `P1 Offensive Faceoffs` + `P2 Offensive Faceoffs` +
      `P1 PM` + `P2 PM` +
      `P1 Powerplays` + `P2 Powerplays` +
      `P1 Penalty Shots` + `P2 Penalty Shots` +
      `P1 Breakaways` + `P2 Breakaways`
    ,family = binomial
    ,data =   hockey_data
  )
summary(hockey_full_logit_02)
goodness_of_fit(hockey_full_logit_02, type = "Chisq")
```

From this we can see that we have two significant parameters at $\alpha=0.05$, and a couple that are close. As well, we can examine the model that only consists of the summed version of the predictors:

```{r Full Model 03}
hockey_full_logit_03<- 
  glm(
    formula = 
      `P1 Win` ~
      Shots + Hits + ToA +
      Passing + Faceoffs + `Offensive Faceoffs` +
      PM + Powerplays + `Penalty Shots` + Breakaways
    ,family = binomial
    ,data =   hockey_data
  )
summary(hockey_full_logit_03)
goodness_of_fit(hockey_full_logit_03, type = "Chisq")
```

We still only have 3 statistically significant parameters, so our model still could use some improvements. What this means we need to do some variable selection. Two methods will be looked at; Stepwise Selection, and LASSO.


## Stepwise Selection
For both directions of the stepwise selection process, BIC with $k=\ln(217)$ is used.

### Backward BIC
```{r Stepwise 01}
hockey_full_logit_02 %>% 
  step(
    direction = "backward"
    ,k = 
      hockey_data %>% 
      count() %>% 
      as.numeric() %>% 
      log()
    ,trace = 0
  ) %>% 
  summary()

hockey_step_logit_01 <- 
  hockey_data %>% 
  glm(
    `P1 Win` ~ `Scored 1st` + `P1 Powerplays` + `P2 Penalty Shots`
    ,family = binomial
    ,data = .
  )
goodness_of_fit(hockey_step_logit_01, type = "Chisq")
goodness_of_fit(hockey_step_logit_01, type = "Gsq")
```

This drastically reduces the number of parameters to 4, giving:
$$
  \operatorname{Logit}\left( \text{P1 Wins} \right) =
  \alpha + \beta_{1}\text{Scored 1st} + \beta_{2}\text{P1 Powerplays} + \beta_{3}\text{P2 Penalty Shots}
$$
$$
  =
  -0.8114 - 1.7359\text{Scored 1st} + 0.2133\text{P1 Powerplays} - 1.5155\text{P2 Penalty Shots}
$$
Where:
$$
  \text{Scored 1st} =
  \begin{cases}
    0,\text{ if P1} \\
    1,\text{ if P2}
  \end{cases}
$$

And the 95\% Confidence intervals for $e^{\beta_{i}}$ are:
```{r Stepwise 01 CI}
hockey_step_logit_01 %>% 
  confint() %>% 
  exp()
```

### Forward BIC
```{r Stepwise 02}
hockey_full_logit_02 %>% 
  step(
    direction = "forward"
    ,k = 
      hockey_data %>% 
      count() %>% 
      as.numeric() %>% 
      log()
    ,trace = 0
  ) %>% 
  summary()
```

Note this is the second full model discussed earlier. Since stepwise selection is almost never used in favor of other methods, and the fact that it gave us some not so useful results, LASSO will be looked at as well in hopes of a better model(Gelman, 2014).


## LASSO
How LASSO regression works is it estimates the value of all the parameters, and starts shrinking them to 0. In this way, LASSO has the advantage of stepwise regression in that it performs both variable selection and coefficient estimation. This is done by manipulating the bias variance trade off. By introducing a bit of bias into the coefficients, the variance of the coefficients can be reduced.

In LASSO regression instead of minimizing $\left(y_{i} - \hat{y}_{i}\right)^{2}$, you minimize $\left|y_{i} - \hat{y}_{i}\right|$. Doing so allows for coefficients to be set to 0, instead of merely near it. The question then becomes, how many coefficients are set to 0? This is accomplished through the use of a tuning parameter $\lambda$, which is in turn determined via the usage of cross-validation. The general rule of thumb for $\lambda$ is to choose it such that the resulting model has 1 standard error than the minimum mean squared error model, in an effort to prevent over fitting.

To do so, the package `glment` is used, specifically the function `cv.glmnet`. Unlike base R, `glmnet` only takes matrices as inputs, so all data frames must be converted to matrices to be used with the model; $\vec{X}$ and $\vec{Y}$.(Hastie et al, 2014)
```{r LASSO Variables}
ind_var_01 <- 
  c(
    "Scored 1st Boolean (P2)"
    ,"P1 Shots"
    ,"P2 Shots"
    ,"P1 Hits"
    ,"P2 Hits"
    ,"P1 ToA"
    ,"P2 ToA"
    ,"P1 Passing"
    ,"P2 Passing"
    ,"P1 PM"
    ,"P2 PM"
    ,"P1 Powerplays"
    ,"P2 Powerplays"
    ,"P1 Faceoffs"
    ,"P2 Faceoffs"
    ,"P1 Breakaways"
    ,"P2 Breakaways"
    ,"P1 Penalty Shots"
    ,"P2 Penalty Shots"
    ,"P1 Offensive Faceoffs"
    ,"P2 Offensive Faceoffs"
  )
ind_var_01

dep_var <- "P1 Win"

hockey_lasso_ind_01 <- 
  hockey_data %>% 
  select(ind_var_01) %>% 
  as.matrix()

hockey_lasso_dep <-
  hockey_data %>% 
  select(dep_var) %>% 
  as.matrix()
```

This is the list of predictor variables that is being used in the first LASSO model:

```{r LASSO Plot}
hockey_lasso_cvfit_01 <-
  cv.glmnet(
    x = hockey_lasso_ind_01
    ,y = hockey_lasso_dep
    ,family = "binomial"
    ,alpha = 1
  )

autoplot(hockey_lasso_cvfit_01)
```

The above chart plots $\ln(\lambda)$ on the x-axis, the $MSE$ on the y-axis, and on the top displays the number of coefficients estimated for a given $\lambda$. The dotted line going through the lower point is our value for $\lambda_{min}=$ `r round(hockey_lasso_cvfit_01$lambda.min, 4)`, and the dotted line going through the higher point is $\lambda_{1se}=$ `r round(hockey_lasso_cvfit_01$lambda.1se, 4)`.

```{r LASSO Coefficients}
hockey_lasso_coef_01_1se <- coef(hockey_lasso_cvfit_01, s = "lambda.1se", exact = TRUE)
hockey_lasso_coef_01_1se

hockey_lasso_coef_01_min <- coef(hockey_lasso_cvfit_01, s = "lambda.min", exact = TRUE)
hockey_lasso_coef_01_min
```

The first output is estimating coefficients using $\lambda_{1se}$, and the latter output is with $\lambda_{min}$. However, because cross-validation is being used in order to estimate $\lambda$, each time the regression is run, different coefficients will arise. As a result of this, it is valuable to do this multiple times and average the results. This can be done by either averaging the coefficients each time the regression is run, or the lambdas themselves.

```{r LASSO Repeated, cache=TRUE}
reps <- 100

hockey_lasso_res_01 <- matrix(nrow = length(ind_var_01) + 1, ncol = reps)
rownames(hockey_lasso_res_01) <- c("(Intercept)", ind_var_01)

hockey_lasso_lambda_01 <- tibble(Min = as.numeric(NA), SE = as.numeric(NA))

for(i in 1:reps){
  hockey_lasso_cvfit_rep <- 
    cv.glmnet(
      x = hockey_lasso_ind_01
      ,y = hockey_lasso_dep
      ,family = "binomial"
      ,alpha = 1
    )
  
  hockey_lasso_coef_rep_min <- 
    hockey_lasso_cvfit_rep %>% 
    coef(s = "lambda.min", exact = TRUE) %>% 
    as.matrix()
  hockey_lasso_res_01[, i] <- hockey_lasso_coef_rep_min
  hockey_lasso_lambda_01[i, "Min"] <- hockey_lasso_cvfit_rep$lambda.min
  hockey_lasso_lambda_01[i, "SE"] <- hockey_lasso_cvfit_rep$lambda.1se
}

apply(X = hockey_lasso_res_01, MARGIN = 1, FUN = mean)

hockey_lasso_avg_lambda <- 
  cv.glmnet(
  x = hockey_lasso_ind_01
  ,y = hockey_lasso_dep
  ,family = "binomial"
  ,alpha = 1
) %>% 
  coef(s = mean(hockey_lasso_lambda_01$Min))
hockey_lasso_avg_lambda
```

The advantage to averaging the $\lambda$s is that when you average the coefficients, if even just 1 time the regression finds an effect, a non-zero effect will appear for that coefficient, which could be unwanted. As such, the averaging of the lambdas will be used, which is the latter of the two models.



# Results
## Model
The LASSO Average Lambda was chosen, due to its superior selection and estimation techniques. This model contained the following variables:

- Scored First
- P1 Shots
- P1 \& P2 Passing
- P1 Power plays
- P1 Breakaways
- P2 Penalty Shots

This gives us the following model:
$$
  \ln\left( \frac{\text{P1 Wins}}{\text{P2 Wins}} \right) =
  -2.2919 - 1.4114\text{Scored First} + 0.0046\text{P1 Shots} + 1.0339\text{P1 Passing} + 1.1588\text{P2 Passing}  
$$
$$
  + 0.1212\text{P1 Powerplays} + 0.0623\text{P1 Breakaways} - 0.5254\text{P2 Penalty Shots}
$$

I would have liked to use a model where the coefficients were averaged, and than any coefficient that appeared in less than $x$\% of the models was set to 0, but I didn't have the opportunity to implement said model, which would be worth looking into going forward. Another possibility would be to find the $\lambda_{Min}$ that minimized the $MSE$ across all models, and use that instead, but again due to time constraints, this wasn't possible.


## Interpretation
By scoring first, a player increases their estimated odds in favor of winning by a multiplicative factor of `r round(exp(-hockey_lasso_avg_lambda["Scored 1st Boolean (P2)",]), 4)`. Only P1's shots was found as a useful predictive measure. Increases the estimated odds in favor by a multiplicative factor of `r round(exp(hockey_lasso_avg_lambda["P1 Shots",]), 4)` per each additional shot. If both players make a lot of their passes, P1's increases their estimated odds in favor of winning by a multiplicative factor of `r round(exp(hockey_lasso_avg_lambda["P1 Passing",]), 4)` for P1 and `r round(exp(hockey_lasso_avg_lambda["P2 Passing",]), 4)` for P2. The more 1-on-0 opportunities given up in a game by a player, the less likely that player will win. For Breakaways this equates to an estimated multiplicative increase by a factor of `r round(exp(hockey_lasso_avg_lambda["P1 Breakaways",]), 4)` and for Penalty Shots an estimated multiplicative increase by a factor of `r round(exp(hockey_lasso_avg_lambda["P2 Penalty Shots",]), 4)`.


## Weaknesses
As with any model, it isn't perfect, so there are some weaknesses. One of which is; what is the real life application of this model? It only really applies to the video game played between these two players, so the results may not be true for any combination of players. As well, who is P1 and P2 in real life? the model would have been potentially more useful if it only include 1 players coefficients, or for each statistic chosen, included both players results, with preferably opposite signs. Passing \% is a example of this, as the higher completion rate by both players, the higher odds P1 has to win, which is unexpected to say the least. One would expect the more passes P2 makes, the odds of winning for P1 would decrease.

As well, the $\lambda_{Min}$ was chosen over $\lambda_{1se}$, as the model was more interesting, as it chose more than one factor. This may be a result in over fitting, and is therefore not advised to do in general practice. As well, LASSO models introduce bias to lower variance, which may be worth examining as well.



\newpage

# References
Gelman, A. (2014, June 02). Why we hate stepwise regression. Retrieved November 29, 2017, from http://andrewgelman.com/2014/06/02/hate-stepwise-regression/

Hastie, T., & Qian, J. (2014, June 26). Glmnet Vignette. Retrieved November 29, 2017, from https://web.stanford.edu/~hastie/glmnet/glmnet_alpha.html

NHL 18 - EA SPORTS - Official Site. (n.d.). Retrieved November 29, 2017, from https://www.easports.com/nhl

R. (n.d.). 2_buds_hockey_stats.xlsx. Retrieved November 29, 2017, from http://randude.com/ps3/

Testing for Autocorrelation. (1999). Retrieved November 29, 2017, from http://www.okstate.edu/sas/v8/sashtml/ets/chap8/sect5.htm

Wickham, H. (n.d.). Tidyverse. Retrieved November 29, 2017, from https://www.tidyverse.org/
