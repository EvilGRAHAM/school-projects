---
title: "Estimation of Banana Weight with a Regression Modeling Approach"
author: "Scott Graham, Kaisa Roggeveen"
date: "February 13, 2018"
output:
  ioslides_presentation:
    smaller: true
    logo: Images/banana.png
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE)
library(pander, warn.conflicts = FALSE, quietly = TRUE)
library(MASS, warn.conflicts = FALSE, quietly = TRUE)
library(DAAG, warn.conflicts = FALSE, quietly = TRUE)
library(caret, warn.conflicts = FALSE, quietly = TRUE)
library(tidyverse, warn.conflicts = FALSE, quietly = TRUE)
library(magrittr, warn.conflicts = FALSE, quietly = TRUE)
library(ggfortify, warn.conflicts = FALSE, quietly = TRUE)
library(knitr, warn.conflicts = FALSE, quietly = TRUE)

set.seed(5609)

theme_minimal2 <- theme_minimal() %>%  theme_set()
theme_minimal2 <-
  theme_update(
    panel.border = element_rect(
      linetype = "solid"
      ,colour = "grey92"
      ,fill = NA
    )
    ,strip.background = element_rect(
      linetype = "solid"
      ,colour = "grey92"
        ,fill = NA
      )
    )

banana_data <-
  "mybanana.txt" %>% 
  read_tsv()
banana_data <-
  banana_data %>% 
  mutate_at(
    .vars = vars(Weight:Circumference)
    ,.funs = funs(log = log)
  )

banana_tidy <- 
  banana_data %>% 
  select(
    -c(
      Weight_log
      ,Radius_log
      ,Length_log
      ,Circumference_log
    )
  ) %>% 
  gather(
    key = "Type"
    ,value = "Measurement"
    ,-ID
  )

banana_reg_02 <-
  banana_data %>% 
  lm(
    Weight_log ~ Length_log + Radius_log
    ,data = .
  )

banana_resid_data <- 
  tibble(
    Predicted = predict(banana_reg_02)
    ,Actual = banana_data$Weight_log
    ,ID = banana_data$ID
    ,`Std Residuals` = stdres(banana_reg_02)
    ,Leverage = hatvalues(banana_reg_02)
  ) %>% 
  mutate(Residual = Actual - Predicted)

banana_data_post <-
  banana_data %>% 
    inner_join(
    banana_resid_data
    ,by = "ID"
  ) %>% 
  filter(
    !(abs(`Std Residuals`) > 2 & Leverage > 0.2)
  ) %>%
  select(
    -c(
      Predicted
      ,Actual
      ,`Std Residuals`
      ,Leverage
      ,Residual
    )
  )

banana_reg_cv <-
  banana_data_post %>%
  cv.lm(
    Weight_log ~ Length_log + Radius_log
    ,plotit = FALSE
  )

banana_train_control <- trainControl(method = "cv", number = 10)
banana_caret_cv <- 
  train(
    Weight_log~.
    ,data = 
      banana_data_post %>% 
      select(Weight_log, Length_log, Radius_log)
    ,trControl = banana_train_control
    ,method = "lm"
  )
```
\[
  \newcommand{\Prob}{\operatorname{P}}
  \newcommand{\E}{\operatorname{E}}
  \newcommand{\Var}{\operatorname{Var}}
  \newcommand{\Cov}{\operatorname{Cov}}
  \newcommand{\se}{\operatorname{se}}
  \newcommand{\re}{\operatorname{re}}
  \newcommand{\ybar}{{\overline{Y}}}
  \newcommand{\phat}{{\hat{p}}}
  \newcommand{\that}{{\hat{T}}}
  \newcommand{\med}{{\tilde{Y}}}
  \newcommand{\Logit}{{\operatorname{Logit}}}
\]

## Removal of Outliers
```{r Outlier Check, fig.height=3}
banana_resid_data %>% 
  ggplot(aes(x = Leverage, y = `Std Residuals`)) +
  geom_hline(
    aes(yintercept = -2)
    ,linetype = "dashed"
  ) +
  geom_hline(
    aes(yintercept = 2)
    ,linetype = "dashed"
  ) +
  geom_point() +
  geom_text(
    data =
      banana_resid_data %>% 
      filter(abs(`Std Residuals`) >= 2)
    ,aes(label = ID)
    ,nudge_x = 0.02
  ) +
  geom_smooth(
    method = "loess"
    ,se = FALSE
  ) +
  geom_smooth(
    method = "lm"
    ,se = FALSE
  ) +
  labs(
    # title = "Figure 6: Standardized Residuals vs. Leverage for Model 02"
    x = "Leverage (ln)"
    ,y = "Standardized Residual (ln)"
  )

banana_data %>% 
  inner_join(
    banana_resid_data %>% 
      filter(abs(`Std Residuals`) > 2)
    ,by = "ID"
  ) %>% 
  select(
    ID
    ,Weight
    ,Radius
    ,Length
    ,Circumference
    ,`Std Residuals`
    ,Leverage
  ) %>% 
  kable(caption = "Entries with a |Standardized Residual| >2")
```


## Recommended Model
After the removal of the outlier, the model that was determined to be the best predictor for banana weight through cross validation was the following:
$$
  \ln(W) = 
  \beta_{0} + \beta_{1}\ln(L) + \beta_{2}\ln(R) \implies
$$
$$
  W =
  0.00193L^{1.028}R^{1.957} \approx
  0.000615\pi LR^{2}
$$
```{r Reg Output}
banana_caret_cv %>% 
  summary() %>% 
  pander(caption = "", style = "rmarkdown")
```

## Cross Validation Error Estimation
### Mean Error
$$
  y_{i} - \hat{y}_{i}
$$

```{r MAE Log}
mae_log <- 
  tibble(
    MSE =
      (
        banana_reg_cv %>% 
          transmute((Weight_log - cvpred)^2) %>% 
          sum()
      )/(as.numeric(count(banana_reg_cv)))
    ,MAE =
      (
        banana_reg_cv %>% 
          transmute(abs(Weight_log - cvpred)) %>% 
          sum()
      )/(as.numeric(count(banana_reg_cv)))
    ,MPAE =
      (
        banana_reg_cv %>% 
          transmute(abs((Weight_log - cvpred) / Weight_log)) %>% 
          sum()
      )/(as.numeric(count(banana_reg_cv)))
  ) %>% 
  mutate(RMSE = sqrt(MSE))
kable(mae_log, caption = "Calculated Error Terms for Log CV Model")
```

$$
  e^{y_{i}} - e^{\hat{y}_{i}}
$$

```{r MAE}
mae_regular <- 
  tibble(
    MSE =
      (
        banana_reg_cv %>% 
          transmute((Weight - exp(cvpred))^2) %>% 
          sum()
      )/(as.numeric(count(banana_reg_cv)))
    ,MAE =
      (
        banana_reg_cv %>% 
          transmute(abs(Weight - exp(cvpred))) %>% 
          sum()
      )/(as.numeric(count(banana_reg_cv)))
    ,MPAE =
      (
        banana_reg_cv %>% 
          transmute(abs((Weight - exp(cvpred)) / Weight)) %>% 
          sum()
      )/(as.numeric(count(banana_reg_cv)))
  ) %>% 
  mutate(RMSE = sqrt(MSE))
kable(mae_regular, caption = "Calculated Error Terms for CV Model")
```


## References
Knofczynski, G. T., & Mundfrom, D. (2007). Sample Sizes When Using Multiple Linear Regression for Prediction. Educational and Psychological Measurement, 68(3), 431-442. doi:10.1177/0013164407310131