---
title: "Snow Gauge Calibration"
author: "Kaisa Roggeveen, Scott Graham"
output:
  ioslides_presentation:
    smaller: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(pander, warn.conflicts = FALSE, quietly = TRUE)
library(knitr, warn.conflicts = FALSE, quietly = TRUE)
library(tidyverse, warn.conflicts = FALSE, quietly = TRUE)
library(ggfortify, warn.conflicts = FALSE, quietly = TRUE)

theme_minimal2 <- theme_minimal() %>%  theme_set()
theme_minimal2 <-
  theme_update(
    panel.border = element_rect(
      linetype = "solid"
      ,colour = "grey92"
      ,fill = NA
    )
    ,strip.background = element_rect(
      linetype = "solid"
      ,colour = "grey92"
      ,fill = NA
    )
  )

# Data Import ----------
snow_wide <- 
  "../Data/snow_data.csv" %>% 
  read_csv()

snow_long <- 
  snow_wide %>% 
  gather(
    key = Gauge
    ,value = Gain
    ,-Density
  ) %>% 
  mutate(Gauge = as.factor(Gauge))

alpha <- 0.05
```
\[
  \newcommand{\Prob}{\operatorname{P}}
  \newcommand{\E}{\operatorname{E}}
  \newcommand{\Var}{\operatorname{Var}}
  \newcommand{\Cov}{\operatorname{Cov}}
  \newcommand{\se}{\operatorname{se}}
  \newcommand{\re}{\operatorname{re}}
  \newcommand{\ybar}{{\overline{Y}}}
  \newcommand{\phat}{{\hat{p}}}
  \newcommand{\that}{{\hat{T}}}
  \newcommand{\med}{{\tilde{Y}}}
  \newcommand{\Logit}{{\operatorname{Logit}}}
\]

# Introduction
## Data
```{r Wide Data}
snow_wide %>% 
  kable()
```


## Log Gain by Gauge
```{r Measured Gain by Gauge}
snow_long %>% 
  ggplot(
    aes(
      x = Gauge
      ,y = log(Gain)
      ,colour = Density
    )
  ) +
  geom_point() +
  facet_grid(
    ~ Gauge
    ,scales = "free_x"
  ) +
  scale_colour_distiller(
    type = "seq"
    ,palette = "OrRd"
    ,direction = 1
  ) +
  labs(
    title = "Figure 01: Measured Gain by Gauge"
    ,colour = expression(paste("Density (g/cm"^3,")"))
  ) +
  theme(
    axis.text.x = element_blank()
    ,axis.title.x = element_blank()
    ,legend.position = "bottom"
  )
```


## Gauge and Density Relationship
```{r Training Data}
snow_long_train <- 
  snow_long %>%
  filter(Gauge %in% c("G 01", "G 02", "G 03"))

snow_long_valid <-
  snow_long %>%
  filter(!(Gauge %in% c("G 01", "G 02", "G 03")))

snow_long_train %>% 
  ggplot(
    aes(
      x = Density
      ,y = log(Gain)
    )
  ) +
  geom_smooth(method = "lm") +
  geom_point() +
  labs(
    title = "Log Gain vs. Density with Training Data"
    ,x = expression(paste("Density (g/cm"^3,")"))
  )
```


# Classic Calibration
## Classic Calibration Method
Let:
$$
  G := \text{Gain},
  D := \text{Density}
$$
$$
  \ln(G) = f(D)
$$
```{r LM}
snow_lm <-
  snow_long_train %>% 
  lm(
      log(Gain) ~ Density
    ,data = .
  )

snow_lm %>% 
  summary() %>% 
  pander()
```


## Classic Calibration Inversion
$$
  \hat{D_{i}} = 
  -\frac{\ln(G_{i}) - 6.0032 - \epsilon_{i}}{4.6301} =
  1.2965(1+\epsilon_{i}) - 0.2160\ln(G_{i}),
  \epsilon_{i} \stackrel{iid}{\sim} \mathcal{N}(0,\sigma^{2})
$$


## Classic Calibration Prediction Interval
$$
  \se\left( \hat{D_{i}} \right) =
  \frac{\sqrt{MSE}}{\hat{\beta_{1}}}\sqrt{1 + \frac{1}{n} + \frac{\left( D_{i}-\bar{D} \right)^{2}}{S_{DD}}}
$$

```{r Classic Calibration Est}
classic_calibration <- function(x, object){
  (log(x) - object$coefficients[["(Intercept)"]]) / object$coefficients[["Density"]]
}

snow_summ_valid_cc <-
  snow_long_valid %>% 
  group_by(Density) %>% 
  summarize(`Mean Gain` = mean(Gain)) %>% 
  mutate(
    `Est Density` = classic_calibration(x = `Mean Gain`, object = snow_lm)
    ,`Prediction Std. Error` = 
      sqrt(
        (summary(snow_lm)$sigma/snow_lm$coefficients[[2]])^2 *
        ( 1 + 
            1/nrow(snow_long_train) + 
            (`Est Density` - mean(snow_long_train$Density))^2/sd(snow_long_train$Density) )
      )
    ,`Prediction LB` = `Est Density` - qt(1-alpha/2, snow_lm$df.residual, lower.tail = TRUE) * `Prediction Std. Error`
    ,`Prediction UB` = `Est Density` + qt(1-alpha/2, snow_lm$df.residual, lower.tail = TRUE) * `Prediction Std. Error`
  )
snow_summ_valid_cc %>% 
  kable()
```


## Classic Calibration Plot
```{r CC Dens vs Gain}
snow_summ_valid_cc %>% 
  ggplot(
    aes(
      x = `Mean Gain`
      ,y = `Est Density`
    )
  ) +
  geom_ribbon(
    aes(
      ymin = `Prediction LB`
      ,ymax = `Prediction UB`
    )
    ,fill = "grey60"
    ,alpha = 0.4
  ) +
  stat_function(
    fun = classic_calibration
    ,args = list(object = snow_lm)
  ) +
  geom_point() +
  labs(
    title = "Estimated Density vs. Gain"
    ,subtitle = "With Prediction Interval and Curve"
    ,y = expression(paste("Estimated Density (g/cm"^3,")"))
  )
```


## Classic Calibration Bias

$$
  \operatorname{bias}\left( \hat{D_{i}} \right) =
  \frac{(D_{i} - \bar{D})MSE}{\hat{\beta_{1}}^{2}S_{DD}}
$$

```{r CC Unbias}
snow_summ_unbias_cc <- 
  snow_summ_valid_cc %>% 
  mutate(
    Bias = 
      (Density - mean(snow_long_train$Density)) * summary(snow_lm)$sigma^2 /
      (snow_lm$coefficients[[2]]^2 * sd(snow_long_train$Density))
    ,`Unbiased Est Density` = `Est Density` - Bias
  ) %>% 
  select(Density, `Est Density`, Bias, `Unbiased Est Density`)
snow_summ_unbias_cc %>% 
  kable()

snow_summ_unbias_cc %>% 
  ggplot(
    aes(
      x = Density
      ,y = Bias
    )
  ) +
  geom_line() +
  labs(
    title = "Rate of Change of Bias"
    ,x = expression(paste("Density (g/cm"^3,")"))
    ,y = expression(paste("Estimated Bias (g/cm"^3,")"))
  )
```


# Inverse Regression
## Inverse Regression Method
$$
  \hat{D_{i}} =
  \hat{\gamma_{0}} + \hat{\gamma_{1}}\left( \ln(G_{i}) - \overline{\ln(G)} \right) + \epsilon_{i},
  \epsilon_{i} \stackrel{iid}{\sim} \mathcal{N}(0,\sigma^{2})
$$
$$
  \overline{\ln(G)} = \sum_{i=1}^{n}\frac{\ln{G_{i}}}{n},
  \hat{\gamma_{0}} = \bar{D}
$$

```{r Inv LM}
snow_inv_lm <-
  snow_long_train %>% 
  mutate(`Centred Gain` = exp(log(Gain) - mean(log(Gain)))) %>% 
  lm(
    Density ~ log(`Centred Gain`)
    ,data = .
  )
snow_inv_lm %>% 
  summary() %>% 
  pander()
```

$$
  \hat{D_{i}} =
  0.3311 - 0.2155\left( \ln(G_{i}) - 4.4701 \right) + \epsilon_{i}
$$


## Inverse Regression Prediction Interval
$$
  \se\left( \hat{D_{i}} \right) =
  \sqrt{MSE}\sqrt{1 + \frac{1}{n} + \frac{\left( \ln(G_{i})-\overline{\ln(G)} \right)^{2}}{S_{GG}}}
$$

```{r Inverse Reg Est}
inverse_regression <- function(x, object){
  predict(object = object, newdata = tibble(`Centred Gain` = exp(log(x) - mean(log(snow_long_train$Gain)))))
}

snow_summ_valid_ir <-
  snow_long_valid %>% 
  group_by(Density) %>% 
  summarize(
    `Mean Gain` = mean(Gain)
  ) %>% 
  mutate(
    `Mean Centred Gain` = exp(log(`Mean Gain`) - mean(log(snow_long_train$Gain)))
  ) %>% 
  mutate(
    `Est Density` = inverse_regression(x = `Mean Gain`, object = snow_inv_lm)
    ,`Prediction Std. Error` =
      sqrt(
        (summary(snow_inv_lm)$sigma)^2 *
          ( 1 +
              1/nrow(snow_long_train) +
              (log(`Mean Gain`) - mean(log(snow_long_train$Gain)))^2/sd(log(snow_long_train$Gain)) )
      )
    ,`Prediction LB` = `Est Density` - qt(1-alpha/2, snow_inv_lm$df.residual, lower.tail = TRUE) * `Prediction Std. Error`
    ,`Prediction UB` = `Est Density` + qt(1-alpha/2, snow_inv_lm$df.residual, lower.tail = TRUE) * `Prediction Std. Error`
  )
snow_summ_valid_ir %>% 
  kable()
```


## Inverse Regression Plot
```{r IR Dens vs Gain}
snow_summ_valid_ir %>% 
  ggplot(
    aes(
      x = `Mean Gain`
      ,y = `Est Density`
    )
  ) +
  geom_ribbon(
    aes(
      ymin = `Prediction LB`
      ,ymax = `Prediction UB`
    )
    ,fill = "grey60"
    ,alpha = 0.4
  ) +
  stat_function(
    fun = inverse_regression
    ,args = list(object = snow_inv_lm)
  ) +
  geom_point() +
  labs(
    title = "Estimated Density vs. Gain"
    ,subtitle = "With Prediction Interval and Curve"
    ,y = expression(paste("Estimated Density (g/cm"^3,")"))
  )
```


## Inverse Regression Bias
$$
  \operatorname{bias}\left( \hat{D_{i}} \right) =
  \frac{\bar{D} - D_{i}}{1 + \frac{\hat{\beta_{1}}^{2}S_{DD}}{(n-1)MSE}}
$$

```{r IR Unbias}
snow_summ_unbias_ir <- 
  snow_summ_valid_ir %>% 
  mutate(
    Bias = 
      (mean(snow_long_train$Density) - Density) /
      (1 + 
         (snow_inv_lm$coefficients[[2]]^2*sd(snow_long_train$Density))/
         ((nrow(snow_long_train) - 1)*summary(snow_inv_lm)$sigma^2)
      )
    ,`Unbiased Est Density` = `Est Density` - Bias
 ) %>% 
  select(Density, `Est Density`, Bias, `Unbiased Est Density`)
snow_summ_unbias_ir %>% 
  kable()

snow_summ_unbias_ir %>% 
  ggplot(
    aes(
      x = Density
      ,y = Bias
    )
  ) +
  geom_line() +
  labs(
    title = "Rate of Change of Bias"
    ,x = expression(paste("Density (g/cm"^3,")"))
    ,y = expression(paste("Estimated Bias (g/cm"^3,")"))
  )
```


# Comparisons
## Bias
```{r Comparison Bias}
snow_summ_unbias_cc %>% 
  select(
    Density
    ,`CC Est Density` = `Est Density`
    ,`CC Bias` = Bias
  ) %>% 
  left_join(
    snow_summ_unbias_ir %>% 
      select(
        Density
        ,`IR Est Density` = `Est Density`
        ,`IR Bias` = Bias
      )
    ,by = "Density"
  ) %>% 
  kable()
```


## Standard Error
```{r Comparison SE}
snow_summ_valid_cc %>% 
  select(
    Density
    ,`Mean Gain`
    ,`CC Est Density` = `Est Density`
    ,`CC Prediction Std. Error` = `Prediction Std. Error`
  ) %>% 
  left_join(
    snow_summ_valid_ir %>% 
      select(  
        Density
        ,`Mean Gain`
        ,`IR Est Density` = `Est Density`
        ,`IR Prediction Std. Error` = `Prediction Std. Error`
      )
    ,by = c("Density" = "Density", "Mean Gain" = "Mean Gain")
  ) %>% 
  kable()
```



# Instructions
## How to Calibrate
Materials Required: Ten different polyethylene blocks with the following densities in g/cm^$3$; 0.001, 0.080, 0.148, 0.223, 0.318, 0.412, 0.508, 0.604 and 0.686.

1. Place a polyethylene block between the snow gauge and measure take ten measurements of the gain. 

2. Calculate the mean gain for the polyethylene block.

3. Using the data set provided, determine if the mean gain falls within the lower and upper bounds for the known density. 
  
  + If the gain does not fall within the bounds for the known density, then adjust the gamma ray emission and repeat until the gain falls within the prediction bound.
  
  + If the gain falls within the prediction bound, mark that the gain was accurately read. Repeat the steps with the next block of known densities until all blocks are reading accurately.


# Measurement Error
## Measurement Error
Let:
$$
  \hat{D_{i}} =
  D_{i} + \epsilon_{D,i},
  \epsilon_{D,i} \sim \mathcal{N}(0, \sigma^{2}) \implies
$$
$$
  \ln(G_{i}) = 
  \hat{\beta_{0}} + \hat{\beta_{1}}\hat{D_{i}} + \epsilon_{G,i} =
  \hat{\beta_{0}} + \hat{\beta_{1}}(D_{i} + \epsilon_{D,i}) + \epsilon_{G,i} =
$$
$$
  \hat{\beta_{0}} + \hat{\beta_{1}}D_{i} + (\hat{\beta_{1}}\epsilon_{D,i} + \epsilon_{G,i}) =
  \hat{\beta_{0}} + \hat{\beta_{1}}D_{i} + \epsilon^{\star}_{G,i}
$$
Where
$$
  \epsilon^{\star}_{G,i} \sim
  \mathcal{N}\left( 0, \hat{\beta_{1}}^{2}\sigma_{D}^{2}+\sigma_{G}^{2}+2\hat{\beta_{1}}\Cov(\epsilon_{D,i},\epsilon_{G,i}) \right)
$$